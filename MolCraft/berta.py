# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/ChemBERTA.ipynb.

# %% auto 0
__all__ = ['get_chemberta']

# %% ../nbs/ChemBERTA.ipynb 4
import torch, numpy as np, pandas as pd,torch.nn as nn
from tqdm import tqdm
from transformers import AutoModelForMaskedLM, AutoTokenizer

# %% ../nbs/ChemBERTA.ipynb 7
@torch.no_grad()
def get_chemberta(df: pd.DataFrame, # dataframe that contains SMILES
                  smi_col: str, # colname of SMILES
                  combine: bool=True, # whether or not combine the mean embeddings and CLS token embedding
                 ):
    
    model = AutoModelForMaskedLM.from_pretrained("DeepChem/ChemBERTa-77M-MTR")
    tokenizer = AutoTokenizer.from_pretrained("DeepChem/ChemBERTa-77M-MTR")

    inputs=tokenizer(df[smi_col].tolist(),return_tensors="pt",padding=True,truncation=True)

    # disable the lm_head so that we only get the transformer output
    model.lm_head =nn.Identity()
    

    out = model(**inputs)[0] # get the logits of the input

    # Get the mean of embeddings
    mean = out.mean(1).numpy()

    # CLS token embedding, from the first token of the seq
    cls = out[:,0,:].numpy()

    if combine:
        emb = np.concatenate([mean,cls],axis=-1)
        emb_df = pd.DataFrame(emb)
        emb_df.columns = 'chemberta_'+emb_df.columns.astype(str)
        emb_df.index=df.index
        return emb_df

    else:
        cls_df = pd.DataFrame(cls)
        mean_df = pd.DataFrame(mean)

        cls_df.columns = 'chemberta_'+cls_df.columns.astype(str)
        mean_df.columns = 'chemberta_'+mean_df.columns.astype(str)

        cls_df.index, mean_df =df.index,df.index

    return cls_df, mean_df
